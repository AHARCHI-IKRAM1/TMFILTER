{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/TangerMedFilter/env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Importations nécessaires\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "from transformers import (\n",
    "    CamembertTokenizer,\n",
    "    CamembertModel,\n",
    "    AdamW,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import nltk\n",
    "import emoji\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Le groupe TangerMed ne se contente pas de gére...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avec une présence stratégique dans 9 ports au ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L'avenir du transport maritime en Afrique pass...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mon Maroc toujours en avant ❤️❤️❤️</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bravo pour un travail brillamment exécuté mon ami</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments  labels\n",
       "0  Le groupe TangerMed ne se contente pas de gére...       1\n",
       "1  Avec une présence stratégique dans 9 ports au ...       1\n",
       "2  L'avenir du transport maritime en Afrique pass...       1\n",
       "3                 Mon Maroc toujours en avant ❤️❤️❤️       1\n",
       "4  Bravo pour un travail brillamment exécuté mon ami       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chargement des données\n",
    "data = pd.read_csv(\"/Users/mac/TangerMedFilter/dataset/DataSetTM.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800 entries, 0 to 799\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   comments  800 non-null    object\n",
      " 1   labels    800 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 12.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='labels'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_counts = data[\"labels\"].value_counts(ascending=True)\n",
    "label_counts.plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    5,   121,    11,  1990,    17,    11,  3215,  3314,    83,    61,\n",
      "          1200,  6840,  1385,    30, 16045,  1313,     6]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Charger le modèle et le tokenizer CamemBERT (camembert-base)\n",
    "model_ckpt = \"camembert-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_ckpt)\n",
    "\n",
    "# Texte à tokenizer\n",
    "text = \"J'adore l'apprentissage automatique ! La tokenisation est géniale !!\"\n",
    "\n",
    "# Tokenisation du texte\n",
    "encoded_text = tokenizer(text, return_tensors=\"pt\")  # return_tensors='pt' pour PyTorch\n",
    "\n",
    "# Affichage des résultats\n",
    "print(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((560, 2), (160, 2), (80, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.3, stratify=data[\"labels\"])\n",
    "test, validation = train_test_split(test, test_size=1 / 3, stratify=test[\"labels\"])\n",
    "train.shape, test.shape, validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['comments', 'labels'],\n",
       "        num_rows: 560\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['comments', 'labels'],\n",
       "        num_rows: 160\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['comments', 'labels'],\n",
       "        num_rows: 80\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict  # Import both Dataset and DatasetDict\n",
    "\n",
    "dataset = DatasetDict(\n",
    "    {\n",
    "        \"train\": Dataset.from_pandas(train, preserve_index=False),\n",
    "        \"test\": Dataset.from_pandas(test, preserve_index=False),\n",
    "        \"validation\": Dataset.from_pandas(validation, preserve_index=False),\n",
    "    }\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commentaire original : Quant à l'argument selon lequel les habitants de la région n'ont pas le niveau d'études pour occuper des postes dans ce port c'est sans fondement. En réalité ceux qui contrôlent les choses...\n",
      "\n",
      "Résultat de la tokenisation : {'input_ids': [5, 2474, 15, 17, 11, 11761, 395, 966, 19, 1384, 8, 13, 581, 49, 11, 263, 34, 16, 359, 18, 11, 4201, 24, 9295, 20, 4045, 29, 44, 1406, 60, 11, 41, 112, 13495, 9, 107, 1033, 320, 31, 963, 113, 19, 541, 57, 6], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "def tokenizer_function(batch):\n",
    "    # Apply tokenization to the 'comments' column in the batch\n",
    "    temp = tokenizer(batch[\"comments\"], padding=True, truncation=True)\n",
    "    return temp\n",
    "\n",
    "\n",
    "# Affichage du commentaire original et du résultat de la tokenisation avec espace\n",
    "original_comment = dataset[\"train\"][0][\"comments\"]\n",
    "tokenized_result = tokenizer_function(dataset[\"train\"][0])\n",
    "\n",
    "# Utilisation de f-strings pour ajouter des espaces et afficher les résultats\n",
    "print(\n",
    "    f\"Commentaire original : {original_comment}\\n\\nRésultat de la tokenisation : {tokenized_result}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "Map:   0%|          | 0/560 [00:00<?, ? examples/s]TOKENIZERS_PARALLELISM=(true | false)\n",
      "Map: 100%|██████████| 560/560 [00:00<00:00, 10806.03 examples/s]\n",
      "Map: 100%|██████████| 160/160 [00:00<00:00, 14634.70 examples/s]\n",
      "Map: 100%|██████████| 80/80 [00:00<00:00, 12967.90 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(tokenizer_function, batched=True, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['comments', 'labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 560\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['comments', 'labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 160\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['comments', 'labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 80\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CamembertModel(\n",
       "  (embeddings): CamembertEmbeddings(\n",
       "    (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): CamembertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x CamembertLayer(\n",
       "        (attention): CamembertAttention(\n",
       "          (self): CamembertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): CamembertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): CamembertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): CamembertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): CamembertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "import torch\n",
    "\n",
    "model = AutoModel.from_pretrained(model_ckpt)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter le mapping des labels au modèle\n",
    "num_labels = 2  # Nombre de classes, ici binaire (ex : négatif, positif)\n",
    "label2id = {\"negatif\": 0, \"positif\": 1}  # Mapping de label à id\n",
    "id2label = {0: \"negatif\", 1: \"positif\"}  # Mapping de id à label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'negatif': 0, 'positif': 1}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'negatif', 1: 'positif'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "num_labels = len(label2id)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class CustomCamembertModel(nn.Module):\n",
    "    def __init__(self, num_labels=2, id2label=id2label, label2id=label2id):\n",
    "        super(CustomCamembertModel, self).__init__()\n",
    "        self.camembert = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_ckpt, num_labels=num_labels\n",
    "        )\n",
    "        self.fc1 = nn.Linear(768, 68)  # Première couche fully-connected\n",
    "        self.fc2 = nn.Linear(68, num_labels)  # Deuxième couche fully-connected\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.id2label = id2label  # Mapping des labels\n",
    "        self.label2id = label2id  # Mapping des labels\n",
    "        self.num_labels = num_labels  # Store num_labels as an attribute\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.camembert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits  # Utiliser les logits directement\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:  # Calculate loss if labels are provided\n",
    "            loss_fct = nn.CrossEntropyLoss()  # Use CrossEntropyLoss for classification\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "\n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "            \"logits\": logits,\n",
    "        }  # Return a dictionary containing loss and logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# Modèle personnalisé basé sur CamemBERT avec une seule couche fully-connected (768 -> 2)\n",
    "class CustomCamembertModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_labels=2,\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "        model_ckpt=\"camembert-base\",\n",
    "    ):\n",
    "        super(CustomCamembertModel, self).__init__()\n",
    "        self.camembert = AutoModelForSequenceClassification.from_pretrained(model_ckpt)\n",
    "        self.fc = nn.Linear(768, num_labels)  # Couche fully-connected unique (768 -> 2)\n",
    "        self.dropout = nn.Dropout(0.1)  # Dropout pour la régularisation\n",
    "        self.id2label = id2label  # Mapping des labels\n",
    "        self.label2id = label2id  # Mapping des labels\n",
    "        self.num_labels = num_labels  # Nombre de classes\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        # Passage du modèle CamemBERT\n",
    "        outputs = self.camembert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_output = outputs.last_hidden_state[\n",
    "            :, 0, :\n",
    "        ]  # Prendre la sortie du token [CLS]\n",
    "\n",
    "        # Application du dropout et de la couche fully-connected\n",
    "        x = self.dropout(cls_output)\n",
    "        logits = self.fc(x)  # Logits pour les classes (2 classes)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = (\n",
    "                nn.CrossEntropyLoss()\n",
    "            )  # Calcul de la loss si les labels sont fournis\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "\n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "            \"logits\": logits,\n",
    "        }  # Retourne un dictionnaire avec la loss et les logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomCamembertModel(\n",
       "  (camembert): CamembertForSequenceClassification(\n",
       "    (roberta): CamembertModel(\n",
       "      (embeddings): CamembertEmbeddings(\n",
       "        (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): CamembertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x CamembertLayer(\n",
       "            (attention): CamembertAttention(\n",
       "              (self): CamembertSdpaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): CamembertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): CamembertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): CamembertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (classifier): CamembertClassificationHead(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. Initialiser le modèle\n",
    "num_labels = len(label2id)\n",
    "model = CustomCamembertModel(num_labels=num_labels)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 'negatif', 1: 'positif'}, {'negatif': 0, 'positif': 1})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.id2label, model.label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/mac/TangerMedFilter/env/lib/python3.12/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/var/folders/97/fhshf9jn3xj5w3sj_t01xqvm0000gn/T/ipykernel_1046/3608285074.py:55: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "  4%|▎         | 10/280 [00:27<08:41,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6869, 'grad_norm': 1.4067420959472656, 'learning_rate': 4.8214285714285716e-05, 'epoch': 0.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 20/280 [00:44<06:59,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6517, 'grad_norm': 1.4573863744735718, 'learning_rate': 4.642857142857143e-05, 'epoch': 0.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 30/280 [01:00<06:40,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5003, 'grad_norm': 1.3782960176467896, 'learning_rate': 4.464285714285715e-05, 'epoch': 0.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 12%|█▎        | 35/280 [01:10<06:34,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.24871177971363068, 'eval_accuracy': 0.9625, 'eval_runtime': 2.5426, 'eval_samples_per_second': 31.464, 'eval_steps_per_second': 3.933, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 40/280 [01:26<10:17,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3291, 'grad_norm': 0.995544970035553, 'learning_rate': 4.2857142857142856e-05, 'epoch': 1.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 50/280 [01:43<06:19,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2782, 'grad_norm': 4.10967493057251, 'learning_rate': 4.107142857142857e-05, 'epoch': 1.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 60/280 [01:59<06:06,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2699, 'grad_norm': 0.5074228048324585, 'learning_rate': 3.928571428571429e-05, 'epoch': 1.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 70/280 [02:16<05:39,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.187, 'grad_norm': 0.6178117394447327, 'learning_rate': 3.7500000000000003e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 25%|██▌       | 70/280 [02:17<05:39,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.13762632012367249, 'eval_accuracy': 0.9625, 'eval_runtime': 1.5639, 'eval_samples_per_second': 51.154, 'eval_steps_per_second': 6.394, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 80/280 [02:39<05:39,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1174, 'grad_norm': 0.5210053324699402, 'learning_rate': 3.571428571428572e-05, 'epoch': 2.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 90/280 [02:56<05:16,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.172, 'grad_norm': 0.42222368717193604, 'learning_rate': 3.392857142857143e-05, 'epoch': 2.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 100/280 [03:12<04:56,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1134, 'grad_norm': 0.238167405128479, 'learning_rate': 3.2142857142857144e-05, 'epoch': 2.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 38%|███▊      | 105/280 [03:22<04:39,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12662310898303986, 'eval_accuracy': 0.9625, 'eval_runtime': 1.7788, 'eval_samples_per_second': 44.973, 'eval_steps_per_second': 5.622, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 110/280 [03:35<05:54,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.081, 'grad_norm': 0.23057009279727936, 'learning_rate': 3.0357142857142857e-05, 'epoch': 3.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 120/280 [03:51<04:15,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0325, 'grad_norm': 201.34645080566406, 'learning_rate': 2.857142857142857e-05, 'epoch': 3.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 130/280 [04:07<04:01,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0737, 'grad_norm': 0.1584167331457138, 'learning_rate': 2.6785714285714288e-05, 'epoch': 3.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 140/280 [04:23<03:41,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1626, 'grad_norm': 0.14340341091156006, 'learning_rate': 2.5e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 50%|█████     | 140/280 [04:24<03:41,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16078229248523712, 'eval_accuracy': 0.9625, 'eval_runtime': 1.4708, 'eval_samples_per_second': 54.392, 'eval_steps_per_second': 6.799, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 150/280 [04:45<03:38,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.043, 'grad_norm': 0.1361168622970581, 'learning_rate': 2.3214285714285715e-05, 'epoch': 4.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 160/280 [05:02<03:11,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0904, 'grad_norm': 0.556605339050293, 'learning_rate': 2.1428571428571428e-05, 'epoch': 4.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 170/280 [05:18<02:55,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0407, 'grad_norm': 0.17086288332939148, 'learning_rate': 1.9642857142857145e-05, 'epoch': 4.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 62%|██████▎   | 175/280 [05:27<02:50,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16745829582214355, 'eval_accuracy': 0.9625, 'eval_runtime': 1.549, 'eval_samples_per_second': 51.648, 'eval_steps_per_second': 6.456, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 180/280 [05:41<03:32,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0136, 'grad_norm': 0.11712806671857834, 'learning_rate': 1.785714285714286e-05, 'epoch': 5.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 190/280 [05:58<02:28,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0273, 'grad_norm': 0.11058270931243896, 'learning_rate': 1.6071428571428572e-05, 'epoch': 5.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 200/280 [06:15<02:12,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0108, 'grad_norm': 0.09552617371082306, 'learning_rate': 1.4285714285714285e-05, 'epoch': 5.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 210/280 [06:31<01:53,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0946, 'grad_norm': 1.7657564878463745, 'learning_rate': 1.25e-05, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 75%|███████▌  | 210/280 [06:33<01:53,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.17555300891399384, 'eval_accuracy': 0.9625, 'eval_runtime': 1.5531, 'eval_samples_per_second': 51.509, 'eval_steps_per_second': 6.439, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 220/280 [06:56<01:54,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0912, 'grad_norm': 25.919326782226562, 'learning_rate': 1.0714285714285714e-05, 'epoch': 6.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 230/280 [07:13<01:23,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0639, 'grad_norm': 0.10684242099523544, 'learning_rate': 8.92857142857143e-06, 'epoch': 6.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 240/280 [07:29<01:05,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0112, 'grad_norm': 0.09721208363771439, 'learning_rate': 7.142857142857143e-06, 'epoch': 6.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 88%|████████▊ | 245/280 [07:39<00:57,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.17875757813453674, 'eval_accuracy': 0.9625, 'eval_runtime': 1.504, 'eval_samples_per_second': 53.191, 'eval_steps_per_second': 6.649, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 250/280 [07:52<01:03,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.036, 'grad_norm': 0.10749895870685577, 'learning_rate': 5.357142857142857e-06, 'epoch': 7.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 260/280 [08:09<00:34,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0106, 'grad_norm': 0.12709349393844604, 'learning_rate': 3.5714285714285714e-06, 'epoch': 7.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 270/280 [08:30<00:22,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0096, 'grad_norm': 0.09321043640375137, 'learning_rate': 1.7857142857142857e-06, 'epoch': 7.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [08:50<00:00,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0685, 'grad_norm': 0.1017472967505455, 'learning_rate': 0.0, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      "100%|██████████| 280/280 [09:08<00:00,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.18098051846027374, 'eval_accuracy': 0.9625, 'eval_runtime': 2.373, 'eval_samples_per_second': 33.713, 'eval_steps_per_second': 4.214, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [09:18<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 558.5722, 'train_samples_per_second': 8.02, 'train_steps_per_second': 0.501, 'train_loss': 0.152395799250475, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Résultats sur l'ensemble d'entraînement ===\n",
      "Accuracy (Train): 0.9625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:05<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Résultats sur l'ensemble de test ===\n",
      "Test Accuracy: 0.9187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:05<00:00,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Rapport de classification pour le jeu de test ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.91        77\n",
      "           1       0.91      0.94      0.92        83\n",
      "\n",
      "    accuracy                           0.92       160\n",
      "   macro avg       0.92      0.92      0.92       160\n",
      "weighted avg       0.92      0.92      0.92       160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, TrainerCallback, AdamW\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Définir les arguments d'entraînement\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./camembert_train_dir\",\n",
    "    eval_strategy=\"epoch\",  # Remplacez `evaluation_strategy` par `eval_strategy`\n",
    "    learning_rate=0.00005,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=8,\n",
    "    weight_decay=0.001,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "\n",
    "# Instancier le modèle avec la bonne architecture pour la classification\n",
    "# model = CustomCamembertModel(num_labels=num_labels)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"camembert-base\", num_labels=num_labels\n",
    ")  # Use AutoModelForSequenceClassification for classification\n",
    "\n",
    "\n",
    "# Fonction pour calculer les métriques\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "    }\n",
    "\n",
    "\n",
    "# Callback pour afficher les métriques\n",
    "class MetricsLogger(TrainerCallback):\n",
    "    def on_epoch_end(self, args, state, control, metrics=None, **kwargs):\n",
    "        if metrics:\n",
    "            print(f\"Époque {state.epoch}/{args.num_train_epochs}:\")\n",
    "            print(f\" - Perte d'entraînement: {metrics['train_loss']:.4f}\")\n",
    "            print(f\" - Précision d'entraînement: {metrics['train_accuracy']:.4f}\")\n",
    "            print(f\" - Perte de validation: {metrics['eval_loss']:.4f}\")\n",
    "            print(f\" - Précision de validation: {metrics['eval_accuracy']:.4f}\\n\")\n",
    "\n",
    "\n",
    "# Créer l'optimiseur\n",
    "optimizer = AdamW(model.parameters(), lr=training_args.learning_rate)\n",
    "\n",
    "# Créer le Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[MetricsLogger()],\n",
    "    optimizers=(\n",
    "        optimizer,\n",
    "        None,\n",
    "    ),  # Passer l'optimiseur, le second est le scheduler (None ici)\n",
    ")\n",
    "\n",
    "# Fine-tuning\n",
    "trainer.train()\n",
    "\n",
    "# Évaluation finale\n",
    "eval_result = trainer.evaluate()\n",
    "print(\"\\n=== Résultats sur l'ensemble d'entraînement ===\")\n",
    "print(f\"Accuracy (Train): {eval_result['eval_accuracy']:.4f}\")\n",
    "\n",
    "# Évaluation finale sur le jeu de test\n",
    "test_result = trainer.evaluate(\n",
    "    eval_dataset=dataset[\"test\"]\n",
    ")  # Assurez-vous d'avoir un dataset 'test'\n",
    "print(\"\\n=== Résultats sur l'ensemble de test ===\")\n",
    "print(f\"Test Accuracy: {test_result['eval_accuracy']:.4f}\")\n",
    "\n",
    "# Obtenez les prédictions pour le rapport de classification\n",
    "test_preds = trainer.predict(dataset[\"test\"])\n",
    "test_labels = test_preds.label_ids\n",
    "test_predictions = np.argmax(test_preds.predictions, axis=1)\n",
    "\n",
    "# Afficher le rapport de classification uniquement à la fin\n",
    "report = classification_report(test_labels, test_predictions)\n",
    "print(\"\\n=== Rapport de classification pour le jeu de test ===\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Sauvegarder le modèle\n",
    "trainer.save_model(\"camembert_sentiment_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le sentiment est : Positif\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Texte à analyser\n",
    "text = \"je suis contente\"\n",
    "\n",
    "# Chargement du modèle de classification\n",
    "classifier = pipeline(\n",
    "    \"text-classification\", model=\"camembert_sentiment_model\", device=-1\n",
    ")\n",
    "\n",
    "# Exécution de la classification\n",
    "result = classifier(text)\n",
    "\n",
    "# Affichage du résultat (positif ou négatif)\n",
    "label = result[0][\"label\"]\n",
    "\n",
    "# Dictionnaire pour la correspondance des labels\n",
    "label_mapping = {\"LABEL_0\": \"Négatif\", \"LABEL_1\": \"Positif\"}\n",
    "\n",
    "# Affichage de la description sans le score\n",
    "description = label_mapping.get(label, label)\n",
    "print(f\"Le sentiment est : {description}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
