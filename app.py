import streamlit as st
import seaborn as sns
from transformers import pipeline
import pandas as pd
import matplotlib.pyplot as plt
from collections import Counter
import re
from nltk.corpus import stopwords
import nltk
from wordcloud import WordCloud
import matplotlib.patches as patches
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from collections import Counter
from wordcloud import WordCloud
import re

# T√©l√©chargement des stop words en fran√ßais
nltk.download("stopwords")
stop_words = set(stopwords.words("french"))
custom_exclusions = {
    "maroc",
    "tanger",
    "port",
    "med",
    "a",
    "√™tre",
    "etre",
    "souvent",
    "gestion",
}

# Configuration de la page Streamlit
st.set_page_config(page_title="Tanger Med - Analyse des Commentaires", layout="wide")

# Style personnalis√©
st.markdown(
    """
    <style>
        .reportview-container {background-color: #1E1E1E; color: #FFFFFF;}
        h1, h2, h3, h4 {color: #004080;}
        .positive-title {color: #66B2FF; font-size: 20px; font-weight: bold;}
        .negative-title {color: red; font-size: 20px; font-weight: bold;}
        .percentage {color: black; font-size: 18px;}
        .stButton>button {background-color: #004080; color: white;}
        .stButton>button:hover {background-color: #007FFF;}
        .graph-container {border: 2px solid #004080; border-radius: 10px; padding: 10px;}
        .wordcloud {border: 2px solid #004080; border-radius: 10px; padding: 10px;}
        .spacer {height: 30px;}
    </style>
""",
    unsafe_allow_html=True,
)

# Titre de l'application
st.markdown(
    """
    <h1 style='text-align: center; font-size: 40px; color: #004080;'>
        üö¢ Tanger Med - Analyse des Commentaires
    </h1>
""",
    unsafe_allow_html=True,
)

# Chargement du mod√®le de classification
classifier = pipeline("text-classification", model="Ikram111/camembert_sentiment_model")


# Option 1 : Analyse en temps r√©el
st.markdown(
    "<span style='color: #D17F36; font-size: 31px;'>üìù Option 1 : Analyse en Temps R√©el</span>",
    unsafe_allow_html=True,
)
user_input = st.text_area(
    "Entrez un ou plusieurs commentaires (s√©par√©s par un saut de ligne uniquement) :"
)

if st.button("Analyser"):
    commentaires = re.split(r"\n+", user_input)
    commentaires = [comment.strip() for comment in commentaires if comment.strip()]

    if commentaires:
        predictions = []
        for idx, commentaire in enumerate(commentaires, 1):
            prediction = classifier(commentaire)[0]["label"]
            sentiment = "Positif" if prediction == "LABEL_1" else "N√©gatif"
            predictions.append(f"Commentaire {idx} : Sentiment pr√©dit -> {sentiment}")

        st.markdown("**R√©sultats des pr√©dictions pour les commentaires**")
        for pred in predictions:
            st.markdown(pred)

st.markdown("<br><br>", unsafe_allow_html=True)
st.markdown(
    "<span style='color: #D17F36; font-size: 31px;'>üìÅ Option 2 : Importer un Fichier CSV</span>",
    unsafe_allow_html=True,
)

# Option 2 : Importation du fichier CSV
uploaded_file = st.file_uploader("Choisissez un fichier CSV", type=["csv"])

if uploaded_file is not None:
    try:
        df = pd.read_csv(uploaded_file)

        if "comments" not in df.columns:
            st.error(
                "Le fichier ne contient pas la colonne 'comments'. Veuillez v√©rifier."
            )
        else:
            st.success("Fichier charg√© avec succ√®s !")
            st.write(df.head())

            # Pr√©dire
            if st.button("Pr√©dire"):
                df["prediction"] = df["comments"].apply(
                    lambda x: classifier(x)[0]["label"]
                )
                label_mapping = {"LABEL_0": "N√©gatif", "LABEL_1": "Positif"}
                df["prediction"] = df["prediction"].map(label_mapping)

                st.markdown("<br>", unsafe_allow_html=True)

                # Affichage des r√©sultats de classification
                st.subheader("R√©sultats de Classification:")
                st.write(
                    df[["comments", "prediction"]]
                )  # Affichez les commentaires avec leurs pr√©dictions

                # Calculer les pourcentages
                total_comments = len(df)
                positif_count = df["prediction"].value_counts().get("Positif", 0)
                negatif_count = df["prediction"].value_counts().get("N√©gatif", 0)

                if total_comments > 0:
                    positif_percentage = (positif_count / total_comments) * 100
                    negatif_percentage = (negatif_count / total_comments) * 100

                    # Utilisation de session_state pour m√©moriser les donn√©es
                    if "class_counts" not in st.session_state:
                        st.session_state.class_counts = df["prediction"].value_counts()

                    # Affichage des r√©sultats en utilisant les deux graphiques c√¥te √† c√¥te
                    st.subheader("Graphique des pr√©dictions:")
                    class_counts = st.session_state.class_counts

                    st.markdown("<br>", unsafe_allow_html=True)

                    # Initialisation des graphiques
                    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))

                    # Graphique en barres
                    colors = [
                        "red" if label == "N√©gatif" else "blue"
                        for label in class_counts.index
                    ]
                    ax1.bar(class_counts.index, class_counts.values, color=colors)

                    ax1.spines["top"].set_visible(False)
                    ax1.spines["right"].set_visible(False)
                    ax1.spines["left"].set_visible(True)
                    ax1.spines["bottom"].set_visible(True)

                    ax1.set_xlabel("Classe")
                    ax1.set_ylabel("Nombre de commentaires")
                    ax1.annotate(
                        "Distribution des Commentaires par Classe",
                        xy=(0.5, -0.2),
                        xycoords="axes fraction",
                        ha="center",
                        fontsize=16,
                    )

                    # Graphique circulaire
                    colors = ["blue", "red"]
                    ax2.pie(
                        class_counts,
                        labels=class_counts.index,
                        autopct="%1.1f%%",
                        colors=colors,
                    )
                    ax2.annotate(
                        "R√©partition des Sentiments",
                        xy=(0.5, -0.2),
                        xycoords="axes fraction",
                        ha="center",
                        fontsize=16,
                    )

                    # Afficher les graphiques
                    st.pyplot(fig)

                    # Affichage des pourcentages sous le graphique
                    st.markdown("<br>", unsafe_allow_html=True)
                    st.subheader("Pourcentages des Sentiments:")
                    st.markdown(
                        "<span class='percentage'>‚Ä¢ Pourcentage Positif : {:.2f}%</span>".format(
                            positif_percentage
                        ),
                        unsafe_allow_html=True,
                    )
                    st.markdown(
                        "<span class='percentage'>‚Ä¢ Pourcentage N√©gatif : {:.2f}%</span>".format(
                            negatif_percentage
                        ),
                        unsafe_allow_html=True,
                    )

                    # Extraction des mots fr√©quents et g√©n√©ration de nuages de mots
                    def get_frequent_words(texts):
                        all_words = " ".join(texts).lower()
                        words = re.findall(r"\w+", all_words)
                        filtered_words = [
                            word
                            for word in words
                            if word not in stop_words and word not in custom_exclusions
                        ]
                        return Counter(filtered_words)

                    positif_texts = df[df["prediction"] == "Positif"][
                        "comments"
                    ].tolist()
                    negatif_texts = df[df["prediction"] == "N√©gatif"][
                        "comments"
                    ].tolist()

                    st.markdown("<br>", unsafe_allow_html=True)

                    st.subheader("Mots Fr√©quents dans les Commentaires Classifi√©s:")

                    st.markdown("<br>", unsafe_allow_html=True)

                    # Affichage des nuages de mots un sur l'autre
                    if positif_texts:
                        st.markdown(
                            """
                            <div style='text-align: center;'>
                                 <span style='font-size: 30px; color:#00BFFF;'> <strong>Mots Fr√©quents pour la Classe Positive</strong></span>
                            </div>
                            """,
                            unsafe_allow_html=True,
                        )
                        positif_words = get_frequent_words(positif_texts)
                        positif_wordcloud = WordCloud(
                            width=400,
                            height=240,
                            background_color="white",
                            colormap="Blues",
                        ).generate_from_frequencies(dict(positif_words))
                        plt.figure(figsize=(6, 4))
                        plt.imshow(positif_wordcloud, interpolation="bilinear")
                        plt.axis("off")
                        st.pyplot(plt.gcf())

                        st.markdown("<br>", unsafe_allow_html=True)

                    if negatif_texts:
                        st.markdown(
                            """
                            <div style='text-align: center;'>
                                 <span style='font-size: 30px; color:red;'><strong>Mots Fr√©quents pour la Classe N√©gative</strong></span>
                            </div>
                            """,
                            unsafe_allow_html=True,
                        )
                        negatif_words = get_frequent_words(negatif_texts)
                        negatif_wordcloud = WordCloud(
                            width=400,
                            height=200,
                            background_color="white",
                            colormap="Reds",
                        ).generate_from_frequencies(dict(negatif_words))
                        plt.figure(figsize=(6, 4))
                        plt.imshow(negatif_wordcloud, interpolation="bilinear")
                        plt.axis("off")

                        # Affichage du nuage de mots avec un cadre
                        st.pyplot(plt.gcf())
                        st.markdown("<br>", unsafe_allow_html=True)

                # T√©l√©chargement des r√©sultats
                st.subheader("T√©l√©charger les r√©sultats de classification:")
                csv = df.to_csv(index=False).encode("utf-8")
                st.download_button(
                    label="T√©l√©charger le fichier CSV",
                    data=csv,
                    file_name="resultats_classification.csv",
                    mime="text/csv",
                )

    except Exception as e:
        st.error(f"Une erreur s'est produite : {e}")

# Instructions suppl√©mentaires pour l'utilisateur, mieux organis√©es et stylis√©es
st.sidebar.title("üìã Instructions d'Utilisation")

st.sidebar.markdown(
    "<span style='color: #D17F36; font-size: 24px;'>üìù Option 1 : Analyse en Temps R√©el</span>",
    unsafe_allow_html=True,
)
st.sidebar.write(
    """
- Entrez vos commentaires dans le champ ci-dessus, s√©par√©s par des sauts de ligne.
- Cliquez sur "Analyser" pour obtenir les pr√©dictions de sentiment.
"""
)

st.sidebar.markdown(
    "<span style='color: #D17F36; font-size: 24px;'>üìÅOption 2 : Importer un Fichier CSV </span>",
    unsafe_allow_html=True,
)

st.sidebar.write(
    """
- T√©l√©chargez votre fichier CSV contenant une colonne nomm√©e 'comments'.
- Cliquez sur "Pr√©dire" pour classer les sentiments de tous les commentaires.
- Vous pouvez √©galement t√©l√©charger les r√©sultats de la classification au format CSV.
"""
)
